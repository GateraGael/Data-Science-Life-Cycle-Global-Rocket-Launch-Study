{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2b5fd97-1734-420e-9a5a-f8d7f6721c8a",
   "metadata": {},
   "source": [
    "# Gunter Space Page\n",
    "\n",
    "Main Website Link: https://space.skyrocket.de/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4239159b-62e7-43c7-9937-a04f541ff59f",
   "metadata": {},
   "source": [
    "## Individual Satellite Data\n",
    "\n",
    "### SAS A (Uhuru, Explorer 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd44fc00-7ddf-4f04-8e2c-af2072d6bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Site URL\n",
    "url=\"https://space.skyrocket.de/doc_sdat/explorer_sas-a.htm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae5cf4f-9b48-48fc-bc43-5d5070698dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a GET request to fetch the raw HTML content\n",
    "html_content = requests.get(url).text\n",
    "\n",
    "# Parse HTML code for the entire site\n",
    "soup = BeautifulSoup(html_content, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68da525-6b65-4380-94b2-6c158b1bd204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tables on site:  2\n"
     ]
    }
   ],
   "source": [
    "# On site there are 3 tables with the class \"wikitable\"\n",
    "# The following line will generate a list of HTML content for each table\n",
    "gdp = soup.find_all(\"table\", attrs={\"class\": \"data\"})\n",
    "print(\"Number of tables on site: \",len(gdp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "69cde3dd-1026-474c-9a48-13fcf63e952a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nation:', 'USA']\n"
     ]
    }
   ],
   "source": [
    "# Lets go ahead and scrape first table with HTML code gdp[0]\n",
    "table1 = gdp[0]\n",
    "# the head will form our column names\n",
    "body = table1.find_all(\"tr\")\n",
    "\n",
    "# Head values (Column names) are the first items of the body list\n",
    "head = body[0] # 0th item is the header row\n",
    "body_rows = body[1:] # All other items becomes the rest of the rows\n",
    "\n",
    "# Lets now iterate through the head HTML code and make list of clean headings\n",
    "\n",
    "# Declare empty list to keep Columns names\n",
    "headings = []\n",
    "for item, item2 in zip(head.find_all(\"th\"), head.find_all(\"td\")): # loop through all th elements\n",
    "    #print(item)\n",
    "    #print(item2)\n",
    "    # convert the th elements to text and strip \"\\n\"\n",
    "    item = (item.text).rstrip(\"\\n\")\n",
    "    item2 = (item2.text).rstrip(\"\\n\")\n",
    "    # append the clean column name to headings\n",
    "    headings.append(item)\n",
    "    headings.append(item2)\n",
    "    \n",
    "print(headings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cefee6af-6ac7-4e77-8426-333e51cd55be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(body_rows[1].find_all(\"th\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50e033b6-7905-41a1-a84d-d62dfff57507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next is now to loop though the rest of the rows\n",
    "\n",
    "#print(body_rows[0])\n",
    "all_rows = [] # will be a list for list for all rows\n",
    "\n",
    "for row_num in range(len(body_rows)): # A row at a time\n",
    "    row = [] # this will old entries for one row\n",
    "    row2 = []\n",
    "    for row_item, row_item2 in zip(body_rows[row_num].find_all(\"th\"), body_rows[row_num].find_all(\"td\")): #loop through all row entries\n",
    "        #print(row_item, row_item2)\n",
    "        #sys.exit()\n",
    "        \n",
    "        # row_item.text removes the tags from the entries\n",
    "        # the following regex is to remove \\xa0 and \\n and comma from row_item.text\n",
    "        # xa0 encodes the flag, \\n is the newline and comma separates thousands in numbers\n",
    "        aa = re.sub(\"(\\xa0)|(\\n)|,\",\"\",row_item.text)\n",
    "        aa2 = re.sub(\"(\\xa0)|(\\n)|,\",\"\",row_item2.text)\n",
    "        #append aa to row - note one row entry is being appended\n",
    "        row.append(aa)\n",
    "        row.append(aa2)\n",
    "        \n",
    "    # append one row to all_rows\n",
    "    all_rows.append(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7ffe6b1-cbc0-41b7-aa6c-25872e0a2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now use the data on all_rowsa and headings to make a table\n",
    "# all_rows becomes our data and headings the column names\n",
    "df = pd.DataFrame(data=all_rows,columns=headings)\n",
    "df.to_csv(\"SAS-A_uhuru_explorer42.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05785329-4331-49b5-b11c-2aab7f5bbf43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
